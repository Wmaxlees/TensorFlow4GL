# =========================
# DEFINITIONS
# =========================
'conv_variables': {
    @SAVE 'conv_variables/W'
    @SUMMARIZE histogram test
    @NAME 'filters'
    VAR tf.random_normal AS filter_variable_1 SIZE(${kernel_size_1}, 1, ${filters_1},)

    @SAVE 'conv_variables/b'
    @SUMMARIZE histogram test
    @NAME 'b'
    VAR tf.zeros AS conv_bias_1 SIZE(${filters_1}, )
}

'fully_connected_variables': {
    @SAVE 'fully_connected_variables/W_1'
    @NAME 'W_1'
    VAR tf.random_normal AS W_1 SIZE(${hidden_layer_size_1}, ${hidden_layer_in}, )

    @SAVE 'fully_connected_variables/W_2'
    @NAME 'W_2'
    VAR tf.random_normal AS W_2 SIZE(1, ${hidden_layer_size_1}, )

    @SAVE 'fully_connected_variables/b_1'
    @NAME 'b_1'
    VAR tf.zeros AS b_1 SIZE(${hidden_layer_size_1}, )

    @SAVE 'fully_connected_variables/b_2'
    @NAME 'b_2'
    VAR tf.zeros AS b_2 SIZE(1, )
}

@NAME 'x'
INPUT x SIZE(None, 134, 46, 1, )

@NAME 'y'
@TRUE_LABELS
INPUT y SIZE(None, 1, )

@NAME 'avg_pool'
OP tf.nn.pool AS average_pooling_0 ARGS(${pool_size_0}, 'AVG', 'VALID')


'conv': {
    OP tf.layers.conv2d AS conv_1 ARGS((1, 1, 1, 1, ))
    OP tf.nn.bias_add AS add_bias
    OP tf.nn.relu6 AS relu_1
    OP tf.layers.batch_norm AS batch_norm_1
    OP tf.nn.dropout AS dropout_1 ARGS(${keep_prob})
}

OP tf.reduce_mean AS filter_out_1 ARGS(axis=3)

OP tf.contrib.layers.flatten AS flattener
OP tf.tensordot AS fully_connected_layer_1 ARGS([[1], [1]])
OP tf.nn.bias_add AS full_bias_1
OP tf.nn.relu6 AS relu_2
OP tf.nn.dropout AS dropout_2 ARGS(${keep_prob})

OP tf.tensordot AS pre_logits ARGS([[1], [1]])

@OUTPUT 0 test
@PREDICTOR
OP tf.nn.bias_add AS logits


# =========================
# FILL VARIABLES
# =========================
USE filter_variable_1 IN conv_1
USE conv_bias_1 IN add_bias
USE W_1 IN fully_connected_layer_1
USE b_1 IN full_bias_1
USE W_2 IN pre_logits
USE b_2 IN logits


# =========================
# GENERATE GRAPH
# =========================
PASS x TO average_pooling_0

PASS average_pooling_0 TO conv_1
PASS conv_1 TO add_bias
PASS add_bias TO relu_1
PASS relu_1 TO batch_norm_1
PASS batch_norm_1 TO dropout_1

PASS dropout_1 TO filter_out_1

PASS filter_out_1 TO flattener
PASS flattener TO fully_connected_layer_1
PASS fully_connected_layer_1 TO full_bias_1 
PASS full_bias_1 TO relu_2
PASS relu_2 TO dropout_2

PASS dropout_2 TO pre_logits
PASS pre_logits TO logits


# =========================
# TRAINING DETAILS
# =========================
'xent': {
    @SUMMARIZE histogram train
    @OUTPUT 0 train
    LOSS tf.losses.sigmoid_cross_entropy
}

@NAME 'training_op'
TRAIN tf.train.Adagrad: ${learning_rate}
